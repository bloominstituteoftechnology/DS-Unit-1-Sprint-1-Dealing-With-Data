{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Okfr_uhwhS1X"
   },
   "source": [
    "# Lambda School Data Science - A First Look at Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "9dtJETFRhnOG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI'd like to see something completely different from what we're used to seeing i.e. Natural Language Processing with NLTK\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lecture - let's explore Python DS libraries and examples!\n",
    "\n",
    "#The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?\n",
    "\"\"\"\n",
    "I'd like to see something completely different from what we're used to seeing i.e. Natural Language Processing with NLTK\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiBkgmPJhmhE"
   },
   "source": [
    "# TODO - we'll be doing this live, taking requests\n",
    "# and reproducing what it is to look up and learn things\n",
    "\n",
    "Natural Language Tool Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOqaPds9huME"
   },
   "source": [
    "## Assignment - now it's your turn\n",
    "\n",
    "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGUS79cOhPWj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score WITH scaled features: 0.97\n",
      "\n",
      "Test set score WITHOUT scaled features: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammylee/miniconda3/envs/datascience/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sammylee/miniconda3/envs/datascience/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO - your code here\n",
    "# Use what we did live in lecture as an example\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Test set score WITH scaled features: {:.2f}\".format(lr.score(X_test_scaled, y_test)))\n",
    "print(\"\\nTest set score WITHOUT scaled features: {:.2f}\".format(lr.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lots of help from Stack Overflow\n",
    "df = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n",
    "                  columns= np.append(cancer['feature_names'], ['target']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234047</td>\n",
       "      <td>0.300643</td>\n",
       "      <td>0.235951</td>\n",
       "      <td>0.133657</td>\n",
       "      <td>0.424483</td>\n",
       "      <td>0.295939</td>\n",
       "      <td>0.187559</td>\n",
       "      <td>0.189911</td>\n",
       "      <td>0.404698</td>\n",
       "      <td>0.290017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229954</td>\n",
       "      <td>0.336354</td>\n",
       "      <td>0.211275</td>\n",
       "      <td>0.112718</td>\n",
       "      <td>0.485159</td>\n",
       "      <td>0.231175</td>\n",
       "      <td>0.277998</td>\n",
       "      <td>0.348797</td>\n",
       "      <td>0.285630</td>\n",
       "      <td>0.275178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550908</td>\n",
       "      <td>0.392289</td>\n",
       "      <td>0.538341</td>\n",
       "      <td>0.411739</td>\n",
       "      <td>0.338178</td>\n",
       "      <td>0.286008</td>\n",
       "      <td>0.253046</td>\n",
       "      <td>0.395179</td>\n",
       "      <td>0.221570</td>\n",
       "      <td>0.097936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591404</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.566367</td>\n",
       "      <td>0.407503</td>\n",
       "      <td>0.326903</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.279663</td>\n",
       "      <td>0.614777</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.091980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380479</td>\n",
       "      <td>0.330402</td>\n",
       "      <td>0.382558</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>0.510698</td>\n",
       "      <td>0.352442</td>\n",
       "      <td>0.343486</td>\n",
       "      <td>0.401938</td>\n",
       "      <td>0.407902</td>\n",
       "      <td>0.168492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386741</td>\n",
       "      <td>0.372601</td>\n",
       "      <td>0.357938</td>\n",
       "      <td>0.231342</td>\n",
       "      <td>0.566664</td>\n",
       "      <td>0.232932</td>\n",
       "      <td>0.394567</td>\n",
       "      <td>0.520275</td>\n",
       "      <td>0.250739</td>\n",
       "      <td>0.213208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230619</td>\n",
       "      <td>0.269530</td>\n",
       "      <td>0.238654</td>\n",
       "      <td>0.127607</td>\n",
       "      <td>0.476393</td>\n",
       "      <td>0.384289</td>\n",
       "      <td>0.181373</td>\n",
       "      <td>0.139115</td>\n",
       "      <td>0.343833</td>\n",
       "      <td>0.443555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153571</td>\n",
       "      <td>0.290245</td>\n",
       "      <td>0.178537</td>\n",
       "      <td>0.072499</td>\n",
       "      <td>0.501460</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>0.250104</td>\n",
       "      <td>0.253265</td>\n",
       "      <td>0.195348</td>\n",
       "      <td>0.326806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188501</td>\n",
       "      <td>0.159959</td>\n",
       "      <td>0.190141</td>\n",
       "      <td>0.099760</td>\n",
       "      <td>0.426198</td>\n",
       "      <td>0.317170</td>\n",
       "      <td>0.157849</td>\n",
       "      <td>0.128926</td>\n",
       "      <td>0.347571</td>\n",
       "      <td>0.376158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130911</td>\n",
       "      <td>0.204158</td>\n",
       "      <td>0.123481</td>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.430143</td>\n",
       "      <td>0.202622</td>\n",
       "      <td>0.187032</td>\n",
       "      <td>0.237732</td>\n",
       "      <td>0.150601</td>\n",
       "      <td>0.222957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.234047      0.300643        0.235951   0.133657         0.424483   \n",
       "1     0.550908      0.392289        0.538341   0.411739         0.338178   \n",
       "2     0.380479      0.330402        0.382558   0.248219         0.510698   \n",
       "3     0.230619      0.269530        0.238654   0.127607         0.476393   \n",
       "4     0.188501      0.159959        0.190141   0.099760         0.426198   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.295939        0.187559             0.189911       0.404698   \n",
       "1          0.286008        0.253046             0.395179       0.221570   \n",
       "2          0.352442        0.343486             0.401938       0.407902   \n",
       "3          0.384289        0.181373             0.139115       0.343833   \n",
       "4          0.317170        0.157849             0.128926       0.347571   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                0.290017           ...                 0.229954   \n",
       "1                0.097936           ...                 0.591404   \n",
       "2                0.168492           ...                 0.386741   \n",
       "3                0.443555           ...                 0.153571   \n",
       "4                0.376158           ...                 0.130911   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0       0.336354         0.211275    0.112718          0.485159   \n",
       "1       0.388060         0.566367    0.407503          0.326903   \n",
       "2       0.372601         0.357938    0.231342          0.566664   \n",
       "3       0.290245         0.178537    0.072499          0.501460   \n",
       "4       0.204158         0.123481    0.058108          0.430143   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0           0.231175         0.277998              0.348797        0.285630   \n",
       "1           0.226562         0.279663              0.614777        0.194362   \n",
       "2           0.232932         0.394567              0.520275        0.250739   \n",
       "3           0.258739         0.250104              0.253265        0.195348   \n",
       "4           0.202622         0.187032              0.237732        0.150601   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                 0.275178  \n",
       "1                 0.091980  \n",
       "2                 0.213208  \n",
       "3                 0.326806  \n",
       "4                 0.222957  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After scaled Data using MinMaxScaler\n",
    "df_2 = pd.DataFrame(X_test_scaled, columns=cancer['feature_names'])\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BT9gdS7viJZa"
   },
   "source": [
    "### Assignment questions\n",
    "\n",
    "After you've worked on some code, answer the following questions in this text block:\n",
    "\n",
    "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
    "\n",
    "2.  What was the most challenging part of what you did?\n",
    "\n",
    "3.  What was the most interesting thing you learned?\n",
    "\n",
    "4.  What area would you like to explore with more time?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the above example, I'm using Logistic Regression algorithm (to demonstrate the sklearn library) which makes predictions based on probability above a threshold (i.e. greater than 50% equals 1, less than 50% equals 0) to make predictions who would/would not get breast cancer based on characteristics such as mean radius and texture of the tumor tissue.  The above model has an accuracy score of 97%.\n",
    "\n",
    "2. This actually wasn't challenging since the dataset automatically comes shipped with sklearn already pre-processed so the hardest task is already done.  \n",
    "\n",
    "3. The most interesting thing I learned was just how much difference scaling can make as I show above.  This is the perfect example of \"garbage in, garbage out\" concept of statistical models.\n",
    "\n",
    "4. I would love to explore one of the most well-tested innovations of data science/ML which is Natural Language Processing and its applications to businesses in the form of recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XXg2crAipwP"
   },
   "source": [
    "## Stretch goals and resources\n",
    "\n",
    "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
    "\n",
    "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
    "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
    "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
    "\n",
    "Stretch goals:\n",
    "\n",
    "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
    "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS DS 111 - A First Look at Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
